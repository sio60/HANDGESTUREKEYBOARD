"""
Hand Gesture Keyboard - FastAPI ë°±ì—”ë“œ ì„œë²„
WebSocketì„ í†µí•œ ì‹¤ì‹œê°„ ì† ì¶”ì  ë°ì´í„° ì „ì†¡
"""
import asyncio
import base64
import json
import cv2
import numpy as np
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse
from contextlib import asynccontextmanager

from hand_tracker import HandTracker, WebcamCapture
from gesture_recognizer import GestureRecognizer


# ì „ì—­ ë³€ìˆ˜
tracker: HandTracker = None
gesture_recognizer: GestureRecognizer = None
webcam: WebcamCapture = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì•± ì‹œì‘/ì¢…ë£Œ ì‹œ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬"""
    global tracker, gesture_recognizer, webcam
    
    print("ğŸ–ï¸ Hand Gesture Keyboard ì„œë²„ ì‹œì‘...")
    tracker = HandTracker(ema_alpha=0.3)
    gesture_recognizer = GestureRecognizer()
    
    try:
        webcam = WebcamCapture(camera_id=0)
        print("âœ… ì›¹ìº  ì—°ê²° ì„±ê³µ")
    except RuntimeError as e:
        print(f"âš ï¸ ì›¹ìº  ì—°ê²° ì‹¤íŒ¨: {e}")
        webcam = None
    
    yield
    
    # ì¢…ë£Œ ì‹œ ë¦¬ì†ŒìŠ¤ í•´ì œ
    if webcam:
        webcam.release()
    if tracker:
        tracker.release()
    print("ğŸ‘‹ ì„œë²„ ì¢…ë£Œ")


app = FastAPI(
    title="Hand Gesture Keyboard API",
    description="ë¹„ì ‘ì´‰ ì œìŠ¤ì²˜ ê¸°ë°˜ ì…ë ¥ ì‹œìŠ¤í…œ",
    version="1.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/")
async def root():
    """API ìƒíƒœ í™•ì¸"""
    return {
        "status": "running",
        "message": "Hand Gesture Keyboard API",
        "webcam_connected": webcam is not None
    }


@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {"status": "healthy"}


@app.websocket("/ws/hand-tracking")
async def websocket_hand_tracking(websocket: WebSocket):
    """
    ì‹¤ì‹œê°„ ì† ì¶”ì  WebSocket ì—”ë“œí¬ì¸íŠ¸
    
    í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡ë˜ëŠ” ë°ì´í„°:
    {
        "type": "tracking",
        "pointer": [x, y],
        "gestures": {
            "pinch": {"is_pinching": bool, "pinch_triggered": bool, ...},
            "fist": {"is_fist": bool, "fist_triggered": bool},
            "dwell": {"dwell_progress": float, "dwell_triggered": bool}
        },
        "hand_detected": bool,
        "frame": "base64_encoded_jpeg"  # ì„ íƒì 
    }
    """
    await websocket.accept()
    print("ğŸ”Œ í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨")
    
    send_video = True  # ë¹„ë””ì˜¤ í”„ë ˆì„ ì „ì†¡ ì—¬ë¶€
    
    try:
        while True:
            # í´ë¼ì´ì–¸íŠ¸ ë©”ì‹œì§€ í™•ì¸ (ë¹„ì°¨ë‹¨)
            try:
                message = await asyncio.wait_for(
                    websocket.receive_text(),
                    timeout=0.001
                )
                data = json.loads(message)
                
                if data.get("type") == "config":
                    send_video = data.get("send_video", True)
                elif data.get("type") == "reset_calibration":
                    if tracker:
                        tracker.reset_calibration()
                        print("ğŸ“ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì´ˆê¸°í™”")
                elif data.get("type") == "calibrate":
                    if tracker and "target" in data:
                        target = data["target"]
                        finger_idx = data.get("finger", 8)
                        # í˜„ì¬ ëœë“œë§ˆí¬ê°€ ìˆì„ ë•Œë§Œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìˆ˜í–‰
                        success, frame = webcam.read()
                        if success:
                            hands_data, _ = tracker.process_frame(frame)
                            if hands_data:
                                # ì²« ë²ˆì§¸ ê°ì§€ëœ ì†ì„ ê¸°ì¤€ìœ¼ë¡œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜
                                tracker.calibrate(hands_data[0]['landmarks'], target, finger_idx)
                                print(f"ğŸ“ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ: Target {target}")
                        
            except asyncio.TimeoutError:
                pass
            except json.JSONDecodeError:
                pass
            
            if webcam is None:
                await websocket.send_json({
                    "type": "error",
                    "message": "ì›¹ìº ì´ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
                })
                await asyncio.sleep(1)
                continue
            
            # í”„ë ˆì„ ìº¡ì²˜
            success, frame = webcam.read()
            if not success:
                await asyncio.sleep(0.01)
                continue
            
            # ì¢Œìš° ë°˜ì „ (ê±°ìš¸ ëª¨ë“œ)
            frame = cv2.flip(frame, 1)
            
            # ì† ì¶”ì 
            # 1. ì† ì¶”ì  (ì´ì œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•¨)
            hands_data, annotated_frame = tracker.process_frame(frame)
            
            # 2. ì œìŠ¤ì²˜ ì¸ì‹
            gesture_results = gesture_recognizer.recognize(hands_data)
            
            # ê²°ê³¼ ì „ì†¡ ê°ì²´ êµ¬ì„±
            response = {
                "type": "tracking",
                "hands": gesture_results, 
                "hand_detected": len(hands_data) > 0
            }
            
            # ë¹„ë””ì˜¤ í”„ë ˆì„ ì „ì†¡ (ì„ íƒì )
            if send_video:
                _, buffer = cv2.imencode('.jpg', annotated_frame, [
                    cv2.IMWRITE_JPEG_QUALITY, 50
                ])
                response["video_frame"] = base64.b64encode(buffer).decode('utf-8')
            
            await websocket.send_json(response)
            
            # í”„ë ˆì„ ë ˆì´íŠ¸ ì œí•œ (~30fps)
            await asyncio.sleep(0.033)
            
    except WebSocketDisconnect:
        print("ğŸ”Œ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í•´ì œ")
    except Exception as e:
        print(f"âŒ WebSocket ì˜¤ë¥˜: {e}")
        await websocket.close()


@app.websocket("/ws/frame-input")
async def websocket_frame_input(websocket: WebSocket):
    """
    í´ë¼ì´ì–¸íŠ¸ì—ì„œ í”„ë ˆì„ì„ ë°›ì•„ ì²˜ë¦¬í•˜ëŠ” WebSocket ì—”ë“œí¬ì¸íŠ¸
    (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì›¹ìº  ì ‘ê·¼ ì‹œ ì‚¬ìš©)
    
    í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë°›ëŠ” ë°ì´í„°:
    {
        "type": "frame",
        "data": "base64_encoded_jpeg"
    }
    """
    await websocket.accept()
    print("ğŸ”Œ í”„ë ˆì„ ì…ë ¥ í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨")
    
    try:
        while True:
            message = await websocket.receive_text()
            data = json.loads(message)
            
            if data.get("type") == "frame" and "data" in data:
                # Base64 ë””ì½”ë”©
                img_bytes = base64.b64decode(data["data"])
                nparr = np.frombuffer(img_bytes, np.uint8)
                frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                
                if frame is None:
                    continue
                
                # ì† ì¶”ì 
                landmarks, _ = tracker.process_frame(frame)
                
                response = {
                    "type": "tracking",
                    "hand_detected": landmarks is not None
                }
                
                if landmarks is not None:
                    gestures = gesture_recognizer.recognize(landmarks)
                    response["pointer"] = list(gestures["pointer"])
                    response["gestures"] = {
                        "pinch": gestures["pinch"],
                        "fist": gestures["fist"],
                        "dwell": gestures["dwell"]
                    }
                
                await websocket.send_json(response)
                
    except WebSocketDisconnect:
        print("ğŸ”Œ í”„ë ˆì„ ì…ë ¥ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í•´ì œ")
    except Exception as e:
        print(f"âŒ WebSocket ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True
    )
